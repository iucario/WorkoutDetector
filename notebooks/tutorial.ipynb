{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial\n",
        "\n",
        "Run this notebook in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LqHGkGEVqpm"
      },
      "source": [
        "## Install MMAction2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "kDo0EiN8_w9s",
        "outputId": "4969764b-fe8e-4c89-9d56-3deede255ffc"
      },
      "outputs": [],
      "source": [
        "# Logs. Not required.\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PAJ4ArzV5Ry",
        "outputId": "0b95b4a5-540e-49e7-f7f9-eed182782694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: mmcv-full 1.5.0\n",
            "Uninstalling mmcv-full-1.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/mmcv/*\n",
            "    /usr/local/lib/python3.7/dist-packages/mmcv_full-1.5.0.dist-info/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled mmcv-full-1.5.0\n",
            "/content/mmaction2/mmaction2/mmaction2\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "%pip install -qqq torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "%pip install -qqq mmcv-full==1.5.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "\n",
        "# Install mmaction2\n",
        "# !rm -rf mmaction2\n",
        "!git clone -q https://github.com/open-mmlab/mmaction2.git\n",
        "%cd mmaction2\n",
        "\n",
        "%pip install -qqq -e .\n",
        "\n",
        "# Install some optional requirements\n",
        "%pip install -qqq -r requirements/optional.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No_zZAFpWC-a",
        "outputId": "140af525-6f38-41bb-dd2e-e406e95c825a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu111 True\n",
            "0.24.0\n",
            "11.1\n",
            "GCC 7.3\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "print(mmaction.__version__)\n",
        "\n",
        "# Check MMCV installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import gc\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLt6s6FJ4KQj"
      },
      "source": [
        "## Download dataest from OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up6UqjRn1wBr"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "def download_onedrive(link):\n",
        "    \"\"\"\n",
        "    link: `https://1drv.ms/u/s!`\n",
        "    \"\"\"\n",
        "    b = base64.urlsafe_b64encode(link.strip().encode('ascii'))\n",
        "    s = b.decode('ascii') # seems that 'Qnc=' is fine\n",
        "    res = f'https://api.onedrive.com/v1.0/shares/u!{s}/root/content'\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvZ7-4ca3XR0",
        "outputId": "f2cf91fc-7261-43f4-ec19-703773743b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-18 00:28:26--  https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3UvcyFBaW9oVjNIUmYtMzRpcHdBQ1lmS1NIaGtaemViclE_ZT1UN1BLSE4=/root/content\n",
            "Resolving api.onedrive.com (api.onedrive.com)... 13.107.42.12\n",
            "Connecting to api.onedrive.com (api.onedrive.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://b32b3w.bl.files.1drv.com/y4mY-S--iClqUx5BDHVHLBMpiUV2A6_wEkGylCdMHjSMhWPRdGtHlRRsbaZe4BrLyGXWFMSrj1Pm8TpIfyxhwdrH-SRAIjsEoroWCzgmGh8XiWjeKhF89-rM43utCRE_b5saIjEvqf3rFGrKZXAdZFeu47kj5Q2uTM0c1wiv1O-8NDDggfVfRiYxVLk9aDs4RrhcIcCO8TaST7eiCD8Nl3ucA/rawf.zip [following]\n",
            "--2022-05-18 00:28:26--  https://b32b3w.bl.files.1drv.com/y4mY-S--iClqUx5BDHVHLBMpiUV2A6_wEkGylCdMHjSMhWPRdGtHlRRsbaZe4BrLyGXWFMSrj1Pm8TpIfyxhwdrH-SRAIjsEoroWCzgmGh8XiWjeKhF89-rM43utCRE_b5saIjEvqf3rFGrKZXAdZFeu47kj5Q2uTM0c1wiv1O-8NDDggfVfRiYxVLk9aDs4RrhcIcCO8TaST7eiCD8Nl3ucA/rawf.zip\n",
            "Resolving b32b3w.bl.files.1drv.com (b32b3w.bl.files.1drv.com)... 13.107.42.12\n",
            "Connecting to b32b3w.bl.files.1drv.com (b32b3w.bl.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8569892988 (8.0G) [application/zip]\n",
            "Saving to: ‘rawframes.zip’\n",
            "\n",
            "rawframes.zip       100%[===================>]   7.98G  31.8MB/s    in 5m 1s   \n",
            "\n",
            "2022-05-18 00:33:28 (27.2 MB/s) - ‘rawframes.zip’ saved [8569892988/8569892988]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# RepCountA\n",
        "onedrive_link = download_onedrive('https://1drv.ms/u/s!AiohV3HRf-34ipwACYfKSHhkZzebrQ?e=T7PKHN')\n",
        "!wget $onedrive_link -O rawframes.zip > /dev/null\n",
        "\n",
        "!unzip rawframes.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgTPIVmv68BG"
      },
      "outputs": [],
      "source": [
        "classes = ['front_raise', 'pull_up', 'squat', 'bench_pressing', 'jump_jack', 'situp',\n",
        "           'push_up', 'others', 'battle_rope', 'pommelhorse']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuZG8kZ2fJ5d"
      },
      "source": [
        "## Train a recognizer on customized dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64CW6d_AaT-Q"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%sh\n",
        "wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_256p_1x1x8_100e_kinetics400_rgb/tsn_r50_256p_1x1x8_100e_kinetics400_rgb_20200817-883baf16.pth \\\n",
        "    -O checkpoints/tsn_r50_256p_1x1x8_100e_kinetics400_rgb_20200817-883baf16.pth "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNZB7NoSabzj"
      },
      "outputs": [],
      "source": [
        "config = 'configs/recognition/tsn/tsn_r50_320p_1x1x8_100e_kinetics400_rgb.py'\n",
        "checkpoint = 'checkpoints/tsn_r50_256p_1x1x8_100e_kinetics400_rgb_20200817-883baf16.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DGJA9jQar"
      },
      "source": [
        "### Modify the config\n",
        "\n",
        "In the next step, we need to modify the config for the training.\n",
        "To accelerate the process, we finetune a recognizer using a pre-trained recognizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlhu9byjjt-K",
        "outputId": "5e9afdac-2ad4-44ba-eabb-ff35a552bdc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model = dict(\n",
            "    type='Recognizer3D',\n",
            "    backbone=dict(\n",
            "        type='ResNet2Plus1d',\n",
            "        depth=34,\n",
            "        pretrained=None,\n",
            "        pretrained2d=False,\n",
            "        norm_eval=False,\n",
            "        conv_cfg=dict(type='Conv2plus1d'),\n",
            "        norm_cfg=dict(type='SyncBN', requires_grad=True, eps=0.001),\n",
            "        conv1_kernel=(3, 7, 7),\n",
            "        conv1_stride_t=1,\n",
            "        pool1_stride_t=1,\n",
            "        inflate=(1, 1, 1, 1),\n",
            "        spatial_strides=(1, 2, 2, 2),\n",
            "        temporal_strides=(1, 2, 2, 2),\n",
            "        zero_init_residual=False),\n",
            "    cls_head=dict(\n",
            "        type='I3DHead',\n",
            "        num_classes=10,\n",
            "        in_channels=512,\n",
            "        spatial_type='avg',\n",
            "        dropout_ratio=0.5,\n",
            "        init_std=0.01),\n",
            "    train_cfg=None,\n",
            "    test_cfg=dict(average_clips='prob'))\n",
            "checkpoint_config = dict(interval=5)\n",
            "log_config = dict(\n",
            "    interval=50,\n",
            "    hooks=[\n",
            "        dict(type='TensorboardLoggerHook'),\n",
            "        dict(\n",
            "            type='WandbLoggerHook',\n",
            "            init_kwargs=dict(\n",
            "                project='RepCount-cleaned',\n",
            "                config=dict(\n",
            "                    model=dict(\n",
            "                        type='Recognizer3D',\n",
            "                        backbone=dict(\n",
            "                            type='ResNet2Plus1d',\n",
            "                            depth=34,\n",
            "                            pretrained=None,\n",
            "                            pretrained2d=False,\n",
            "                            norm_eval=False,\n",
            "                            conv_cfg=dict(type='Conv2plus1d'),\n",
            "                            norm_cfg=dict(\n",
            "                                type='SyncBN', requires_grad=True, eps=0.001),\n",
            "                            conv1_kernel=(3, 7, 7),\n",
            "                            conv1_stride_t=1,\n",
            "                            pool1_stride_t=1,\n",
            "                            inflate=(1, 1, 1, 1),\n",
            "                            spatial_strides=(1, 2, 2, 2),\n",
            "                            temporal_strides=(1, 2, 2, 2),\n",
            "                            zero_init_residual=False),\n",
            "                        cls_head=dict(\n",
            "                            type='I3DHead',\n",
            "                            num_classes=10,\n",
            "                            in_channels=512,\n",
            "                            spatial_type='avg',\n",
            "                            dropout_ratio=0.5,\n",
            "                            init_std=0.01),\n",
            "                        train_cfg=None,\n",
            "                        test_cfg=dict(average_clips='prob')),\n",
            "                    checkpoint_config=dict(interval=5),\n",
            "                    log_config=dict(\n",
            "                        interval=20, hooks=[dict(type='TextLoggerHook')]),\n",
            "                    dist_params=dict(backend='nccl'),\n",
            "                    log_level='INFO',\n",
            "                    load_from=None,\n",
            "                    resume_from=None,\n",
            "                    workflow=[('train', 1)],\n",
            "                    opencv_num_threads=0,\n",
            "                    mp_start_method='fork',\n",
            "                    dataset_type='RawframeDataset',\n",
            "                    data_root='/content/mmaction2/rawframes/train',\n",
            "                    data_root_val='/content/mmaction2/rawframes/val',\n",
            "                    ann_file_train=\n",
            "                    '/content/mmaction2/rawframes/rawframes_train.txt',\n",
            "                    ann_file_val=\n",
            "                    '/content/mmaction2/rawframes/rawframes_val.txt',\n",
            "                    ann_file_test=\n",
            "                    '/content/mmaction2/rawframes/rawframes_test.txt',\n",
            "                    img_norm_cfg=dict(\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_bgr=False),\n",
            "                    train_pipeline=[\n",
            "                        dict(\n",
            "                            type='SampleFrames',\n",
            "                            clip_len=8,\n",
            "                            frame_interval=8,\n",
            "                            num_clips=1),\n",
            "                        dict(type='RawFrameDecode'),\n",
            "                        dict(type='Resize', scale=(-1, 256)),\n",
            "                        dict(type='RandomResizedCrop'),\n",
            "                        dict(\n",
            "                            type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "                        dict(type='Flip', flip_ratio=0.5),\n",
            "                        dict(\n",
            "                            type='Normalize',\n",
            "                            mean=[123.675, 116.28, 103.53],\n",
            "                            std=[58.395, 57.12, 57.375],\n",
            "                            to_bgr=False),\n",
            "                        dict(type='FormatShape', input_format='NCTHW'),\n",
            "                        dict(\n",
            "                            type='Collect',\n",
            "                            keys=['imgs', 'label'],\n",
            "                            meta_keys=[]),\n",
            "                        dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "                    ],\n",
            "                    val_pipeline=[\n",
            "                        dict(\n",
            "                            type='SampleFrames',\n",
            "                            clip_len=8,\n",
            "                            frame_interval=8,\n",
            "                            num_clips=1,\n",
            "                            test_mode=True),\n",
            "                        dict(type='RawFrameDecode'),\n",
            "                        dict(type='Resize', scale=(-1, 256)),\n",
            "                        dict(type='CenterCrop', crop_size=224),\n",
            "                        dict(\n",
            "                            type='Normalize',\n",
            "                            mean=[123.675, 116.28, 103.53],\n",
            "                            std=[58.395, 57.12, 57.375],\n",
            "                            to_bgr=False),\n",
            "                        dict(type='FormatShape', input_format='NCTHW'),\n",
            "                        dict(\n",
            "                            type='Collect',\n",
            "                            keys=['imgs', 'label'],\n",
            "                            meta_keys=[]),\n",
            "                        dict(type='ToTensor', keys=['imgs'])\n",
            "                    ],\n",
            "                    test_pipeline=[\n",
            "                        dict(\n",
            "                            type='SampleFrames',\n",
            "                            clip_len=8,\n",
            "                            frame_interval=8,\n",
            "                            num_clips=10,\n",
            "                            test_mode=True),\n",
            "                        dict(type='RawFrameDecode'),\n",
            "                        dict(type='Resize', scale=(-1, 256)),\n",
            "                        dict(type='ThreeCrop', crop_size=256),\n",
            "                        dict(\n",
            "                            type='Normalize',\n",
            "                            mean=[123.675, 116.28, 103.53],\n",
            "                            std=[58.395, 57.12, 57.375],\n",
            "                            to_bgr=False),\n",
            "                        dict(type='FormatShape', input_format='NCTHW'),\n",
            "                        dict(\n",
            "                            type='Collect',\n",
            "                            keys=['imgs', 'label'],\n",
            "                            meta_keys=[]),\n",
            "                        dict(type='ToTensor', keys=['imgs'])\n",
            "                    ],\n",
            "                    data=dict(\n",
            "                        videos_per_gpu=1,\n",
            "                        workers_per_gpu=2,\n",
            "                        test_dataloader=dict(videos_per_gpu=1),\n",
            "                        train=dict(\n",
            "                            type='RawframeDataset',\n",
            "                            ann_file=\n",
            "                            '/content/mmaction2/rawframes/rawframes_train.txt',\n",
            "                            data_prefix='/content/mmaction2/rawframes/train',\n",
            "                            pipeline=[\n",
            "                                dict(\n",
            "                                    type='SampleFrames',\n",
            "                                    clip_len=8,\n",
            "                                    frame_interval=8,\n",
            "                                    num_clips=1),\n",
            "                                dict(type='RawFrameDecode'),\n",
            "                                dict(type='Resize', scale=(-1, 256)),\n",
            "                                dict(type='RandomResizedCrop'),\n",
            "                                dict(\n",
            "                                    type='Resize',\n",
            "                                    scale=(224, 224),\n",
            "                                    keep_ratio=False),\n",
            "                                dict(type='Flip', flip_ratio=0.5),\n",
            "                                dict(\n",
            "                                    type='Normalize',\n",
            "                                    mean=[123.675, 116.28, 103.53],\n",
            "                                    std=[58.395, 57.12, 57.375],\n",
            "                                    to_bgr=False),\n",
            "                                dict(type='FormatShape', input_format='NCTHW'),\n",
            "                                dict(\n",
            "                                    type='Collect',\n",
            "                                    keys=['imgs', 'label'],\n",
            "                                    meta_keys=[]),\n",
            "                                dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "                            ]),\n",
            "                        val=dict(\n",
            "                            type='RawframeDataset',\n",
            "                            ann_file=\n",
            "                            '/content/mmaction2/rawframes/rawframes_val.txt',\n",
            "                            data_prefix='/content/mmaction2/rawframes/val',\n",
            "                            pipeline=[\n",
            "                                dict(\n",
            "                                    type='SampleFrames',\n",
            "                                    clip_len=8,\n",
            "                                    frame_interval=8,\n",
            "                                    num_clips=1,\n",
            "                                    test_mode=True),\n",
            "                                dict(type='RawFrameDecode'),\n",
            "                                dict(type='Resize', scale=(-1, 256)),\n",
            "                                dict(type='CenterCrop', crop_size=224),\n",
            "                                dict(\n",
            "                                    type='Normalize',\n",
            "                                    mean=[123.675, 116.28, 103.53],\n",
            "                                    std=[58.395, 57.12, 57.375],\n",
            "                                    to_bgr=False),\n",
            "                                dict(type='FormatShape', input_format='NCTHW'),\n",
            "                                dict(\n",
            "                                    type='Collect',\n",
            "                                    keys=['imgs', 'label'],\n",
            "                                    meta_keys=[]),\n",
            "                                dict(type='ToTensor', keys=['imgs'])\n",
            "                            ],\n",
            "                            test_mode=True),\n",
            "                        test=dict(\n",
            "                            type='RawframeDataset',\n",
            "                            ann_file=\n",
            "                            '/content/mmaction2/rawframes/rawframes_test.txt',\n",
            "                            data_prefix='/content/mmaction2/rawframes/test',\n",
            "                            pipeline=[\n",
            "                                dict(\n",
            "                                    type='SampleFrames',\n",
            "                                    clip_len=8,\n",
            "                                    frame_interval=8,\n",
            "                                    num_clips=10,\n",
            "                                    test_mode=True),\n",
            "                                dict(type='RawFrameDecode'),\n",
            "                                dict(type='Resize', scale=(-1, 256)),\n",
            "                                dict(type='ThreeCrop', crop_size=256),\n",
            "                                dict(\n",
            "                                    type='Normalize',\n",
            "                                    mean=[123.675, 116.28, 103.53],\n",
            "                                    std=[58.395, 57.12, 57.375],\n",
            "                                    to_bgr=False),\n",
            "                                dict(type='FormatShape', input_format='NCTHW'),\n",
            "                                dict(\n",
            "                                    type='Collect',\n",
            "                                    keys=['imgs', 'label'],\n",
            "                                    meta_keys=[]),\n",
            "                                dict(type='ToTensor', keys=['imgs'])\n",
            "                            ],\n",
            "                            test_mode=True)),\n",
            "                    evaluation=dict(\n",
            "                        interval=5,\n",
            "                        metrics=['top_k_accuracy', 'mean_class_accuracy'],\n",
            "                        save_best='auto'),\n",
            "                    optimizer=dict(\n",
            "                        type='SGD',\n",
            "                        lr=0.00078125,\n",
            "                        momentum=0.9,\n",
            "                        weight_decay=0.0001),\n",
            "                    optimizer_config=dict(\n",
            "                        grad_clip=dict(max_norm=40, norm_type=2)),\n",
            "                    lr_config=dict(policy='CosineAnnealing', min_lr=0),\n",
            "                    total_epochs=100,\n",
            "                    work_dir=\n",
            "                    './work_dirs/r2plus1d_r34_8x8x1_180e_kinetics400_rgb/',\n",
            "                    find_unused_parameters=False,\n",
            "                    omnisource=False,\n",
            "                    seed=0,\n",
            "                    gpu_ids=range(0, 1))))\n",
            "    ])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "dataset_type = 'RawframeDataset'\n",
            "data_root = '/content/mmaction2/rawframes/train'\n",
            "data_root_val = '/content/mmaction2/rawframes/val'\n",
            "ann_file_train = '/content/mmaction2/rawframes/rawframes_train.txt'\n",
            "ann_file_val = '/content/mmaction2/rawframes/rawframes_val.txt'\n",
            "ann_file_test = '/content/mmaction2/rawframes/rawframes_test.txt'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
            "train_pipeline = [\n",
            "    dict(type='SampleFrames', clip_len=8, frame_interval=8, num_clips=1),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='RandomResizedCrop'),\n",
            "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCTHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=8,\n",
            "        frame_interval=8,\n",
            "        num_clips=1,\n",
            "        test_mode=True),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCTHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=8,\n",
            "        frame_interval=8,\n",
            "        num_clips=10,\n",
            "        test_mode=True),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='ThreeCrop', crop_size=256),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCTHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "data = dict(\n",
            "    videos_per_gpu=1,\n",
            "    workers_per_gpu=2,\n",
            "    test_dataloader=dict(videos_per_gpu=1),\n",
            "    train=dict(\n",
            "        type='RawframeDataset',\n",
            "        ann_file='/content/mmaction2/rawframes/rawframes_train.txt',\n",
            "        data_prefix='/content/mmaction2/rawframes/train',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=8, frame_interval=8,\n",
            "                num_clips=1),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='RandomResizedCrop'),\n",
            "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCTHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='RawframeDataset',\n",
            "        ann_file='/content/mmaction2/rawframes/rawframes_val.txt',\n",
            "        data_prefix='/content/mmaction2/rawframes/val',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=8,\n",
            "                frame_interval=8,\n",
            "                num_clips=1,\n",
            "                test_mode=True),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCTHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ],\n",
            "        test_mode=True),\n",
            "    test=dict(\n",
            "        type='RawframeDataset',\n",
            "        ann_file='/content/mmaction2/rawframes/rawframes_test.txt',\n",
            "        data_prefix='/content/mmaction2/rawframes/test',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=8,\n",
            "                frame_interval=8,\n",
            "                num_clips=10,\n",
            "                test_mode=True),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='ThreeCrop', crop_size=256),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCTHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ],\n",
            "        test_mode=True))\n",
            "evaluation = dict(\n",
            "    interval=5,\n",
            "    metrics=['top_k_accuracy', 'mean_class_accuracy'],\n",
            "    save_best='auto')\n",
            "optimizer = dict(type='SGD', lr=0.00078125, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
            "lr_config = dict(policy='CosineAnnealing', min_lr=0)\n",
            "total_epochs = 100\n",
            "work_dir = './work_dirs/r2plus1d_r34_8x8x1_180e_kinetics400_rgb/'\n",
            "find_unused_parameters = False\n",
            "omnisource = False\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmcv import Config\n",
        "import os.path as osp\n",
        "cfg = Config.fromfile(config)\n",
        "\n",
        "from mmcv.runner import set_random_seed\n",
        "DATASET = '/content/mmaction2/rawframes/'\n",
        "NUM_CLASSES = len(classes)\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'RawframeDataset'\n",
        "cfg.data_root = DATASET + 'train'\n",
        "cfg.data_root_val = DATASET + 'val'\n",
        "cfg.ann_file_train = DATASET +'rawframes_train.txt'\n",
        "cfg.ann_file_val = DATASET +'rawframes_val.txt'\n",
        "cfg.ann_file_test = DATASET +'rawframes_test.txt'\n",
        "\n",
        "cfg.data.test.ann_file = cfg.ann_file_test\n",
        "cfg.data.test.data_prefix = DATASET + 'test'\n",
        "\n",
        "cfg.data.train.ann_file = cfg.ann_file_train\n",
        "cfg.data.train.data_prefix = cfg.data_root\n",
        "\n",
        "cfg.data.val.ann_file = cfg.ann_file_val\n",
        "cfg.data.val.data_prefix = cfg.data_root_val\n",
        "\n",
        "cfg.setdefault('omnisource', False)\n",
        "\n",
        "cfg.model.cls_head.num_classes = NUM_CLASSES\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.data.videos_per_gpu = max(1, cfg.data.videos_per_gpu // 8)\n",
        "cfg.optimizer.lr = cfg.optimizer.lr / 8 / 16\n",
        "cfg.total_epochs = 100\n",
        "cfg.load_from = checkpoint\n",
        "# cfg.resume_from = osp.join(cfg.work_dir, 'latest.pth')\n",
        "cfg.checkpoint_config.interval = 5\n",
        "\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# Save the best\n",
        "cfg.evaluation.save_best='auto'\n",
        "\n",
        "cfg.log_config = dict(\n",
        "    interval=50,\n",
        "    hooks=[\n",
        "        # dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook'),\n",
        "        dict(type='WandbLoggerHook', init_kwargs=dict(project='RepCount-cleaned', \n",
        "                                                      config={**cfg})),\n",
        "])\n",
        "\n",
        "print(cfg.pretty_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES-qnZ3k38Z"
      },
      "source": [
        "### Train a new recognizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "af7eaffa7371427099c54f262e505b59"
          ]
        },
        "id": "dDBWkdDRk6oz",
        "outputId": "f3447489-bec8-4438-d7b3-606dfbdf065f"
      },
      "outputs": [],
      "source": [
        "from mmaction.datasets import build_dataset\n",
        "from mmaction.models import build_model\n",
        "from mmaction.apis import train_model\n",
        "\n",
        "import mmcv\n",
        "\n",
        "# Build the dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the recognizer\n",
        "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_model(model, datasets, cfg, distributed=False, validate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVoSfZVmogw"
      },
      "source": [
        "## Test the trained recognizer\n",
        "\n",
        "After finetuning the recognizer, let's check the prediction results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyY3hCMwyTct",
        "outputId": "6b615ea8-cfcd-4217-88a8-eca5608ae2e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 152/152, 2.4 task/s, elapsed: 64s, ETA:     0s\n",
            "Evaluating top_k_accuracy ...\n",
            "\n",
            "top1_acc\t0.8487\n",
            "top5_acc\t0.9737\n",
            "\n",
            "Evaluating mean_class_accuracy ...\n",
            "\n",
            "mean_acc\t0.7613\n",
            "top1_acc: 0.8487\n",
            "top5_acc: 0.9737\n",
            "mean_class_accuracy: 0.7613\n"
          ]
        }
      ],
      "source": [
        "from mmaction.apis import single_gpu_test\n",
        "from mmaction.datasets import build_dataloader\n",
        "from mmcv.parallel import MMDataParallel\n",
        "\n",
        "# Build a test dataloader\n",
        "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
        "data_loader = build_dataloader(\n",
        "        dataset,\n",
        "        videos_per_gpu=1,\n",
        "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "        dist=False,\n",
        "        shuffle=False)\n",
        "model = MMDataParallel(model, device_ids=[0])\n",
        "outputs = single_gpu_test(model, data_loader)\n",
        "\n",
        "eval_config = cfg.evaluation\n",
        "eval_config.pop('interval')\n",
        "eval_res = dataset.evaluate(outputs, **eval_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_GFszaT7Msr",
        "outputId": "481b2345-16b8-4571-e734-a82fc3dcf2f4"
      },
      "outputs": [],
      "source": [
        "# Test on best model\n",
        "best_model_path = '/content/mmaction2/work_dirs/tsn_r50_320p_1x1x8_100e_kinetics400_rgb/lastest.pth'\n",
        "best_cfg = cfg\n",
        "best_cfg.load_from = best_model_path\n",
        "model_best = build_model(cfg.model, test_cfg=best_cfg.get('test_cfg'))\n",
        "model_best = MMDataParallel(model_best, device_ids=[0])\n",
        "outputs = single_gpu_test(model_best, data_loader)\n",
        "\n",
        "eval_config = cfg.evaluation\n",
        "eval_res = dataset.evaluate(outputs, **eval_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbs3XeWR2ia"
      },
      "source": [
        "### Inference Youtube videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzRYQxt175Zg",
        "outputId": "9013af3e-1c71-44ff-c553-d5641dfdaa3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 357 kB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 35.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 218 kB 54.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 49.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install yt-dlp -qqq\n",
        "import yt_dlp\n",
        "\n",
        "import os\n",
        "def download_ytb(url, folder):\n",
        "    # vid = url.split('?v=')[1]\n",
        "    # link = url + vid\n",
        "    ydl_opts = {\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        'quiet': True,\n",
        "        'ignoreerrors': True,\n",
        "        'format': '136',  # 136 for mp4 1280x720 25fps no audio. 137: 1080P\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modify config for video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMtqYwzppk52",
        "outputId": "26520b15-0af0-439c-fa8f-6bdaedfb105b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load checkpoint from local path: /content/mmaction2/work_dirs/tsm_r50_1x1x16_50e_sthv2_rgb/best_top1_acc_epoch_58.pth\n"
          ]
        }
      ],
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "\n",
        "test_cfg = cfg\n",
        "test_cfg.dataset_type = 'VideoDataset'\n",
        "test_cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
        "test_cfg.test_pipeline = [\n",
        "    dict(type='DecordInit', num_threads=1),\n",
        "    dict(\n",
        "        type='SampleFrames',\n",
        "        clip_len=1,\n",
        "        frame_interval=1,\n",
        "        num_clips=16,\n",
        "        test_mode=True),\n",
        "    dict(type='DecordDecode'),\n",
        "    dict(type='Resize', scale=(-1, 256)),\n",
        "    dict(type='CenterCrop', crop_size=224),\n",
        "    dict(type='Normalize', **test_cfg.img_norm_cfg),\n",
        "    dict(type='FormatShape', input_format='NCHW'),\n",
        "    dict(type='Collect', keys=['imgs'], meta_keys=[]),\n",
        "    dict(type='ToTensor', keys=['imgs'])\n",
        "]\n",
        "\n",
        "test_cfg.data = dict(\n",
        "    videos_per_gpu=1,\n",
        "    workers_per_gpu=2,\n",
        "    test=dict(\n",
        "        type=test_cfg.dataset_type,\n",
        "        ann_file=None,\n",
        "        data_prefix=None,\n",
        "        pipeline=test_cfg.test_pipeline))\n",
        "\n",
        "ckpt = '/content/mmaction2/work_dirs/tsn_r50_320p_1x1x8_100e_kinetics400_rgb/lastest.pth'\n",
        "model_video = init_recognizer(test_cfg, ckpt, device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG9FqyJ99TjR",
        "outputId": "f51b4c77-83e3-4877-de35-14e08fcbc742"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[download] 100% of 5.83MiB in 00:00                                                  "
          ]
        }
      ],
      "source": [
        "url = 'https://www.youtube.com/watch?v=kRX2NfqM90g'\n",
        "FILENAME = url[-11:]+'.mp4'\n",
        "download_ytb(url, 'demo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYGxdu8Vnoah"
      },
      "source": [
        "### Run demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76fR-8dY-43T",
        "outputId": "b6618d46-6dfc-4595-f24a-10f401cf9eca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(2, 0.7956046), (3, 0.20423073), (8, 4.4019278e-05), (6, 3.4168923e-05), (1, 3.166302e-05)]\n",
            "0.7956045866012573, squat\n",
            "0.20423072576522827, bench_pressing\n",
            "4.401927799335681e-05, battle_rope\n",
            "3.416892286622897e-05, push_up\n",
            "3.1663021218264475e-05, pull_up\n"
          ]
        }
      ],
      "source": [
        "results = inference_recognizer(model_video, FILENAME)\n",
        "for r in results:\n",
        "    print(f'{classes[r[0]]}, {r[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "-0atQCzBo9-C",
        "outputId": "e383dd79-282d-4a14-fc44-665a253c3811"
      },
      "outputs": [],
      "source": [
        "# Check the video\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open( FILENAME,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=600 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of MMAction2 Tutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
