{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as osj\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import json\n",
    "from workoutdetector.datasets import RepcountHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['lines.linewidth'] = 0.8\n",
    "COLORS = list(plt.get_cmap('Set3').colors)\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler('color', COLORS)\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = RepcountHelper('../data/RepCount/', '../data/RepCount/annotation.csv') \n",
    "info = helper.get_rep_data(['test'], action=['all'])\n",
    "CLASSES = helper.classes\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [x for x in os.listdir('../out/pred_no_bbox/') if x.endswith('.json')]\n",
    "json_iter = iter(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = next(json_iter)\n",
    "name = json_file.split('-')[0]\n",
    "print(name)\n",
    "example = json.load(open(f'../out/pred_no_bbox/{name}-score.json'))\n",
    "scores = np.asarray([v for _, v in example['scores'].items()])\n",
    "print('total frames', len(scores))\n",
    "print('reps', info[name].reps)\n",
    "\n",
    "plt.plot(F.softmax(torch.Tensor(scores), dim=1))\n",
    "plt.vlines(x=info[name].reps, color='C2', ymin=0.4, ymax=0.6)\n",
    "plt.title(f'{name} {info[name].class_} Count={info[name].count}', color='C0', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_save_dir = '../out/tsm_rep_scores_dense_sample'\n",
    "video_json = os.listdir(video_save_dir)\n",
    "print(video_json[0])\n",
    "video_iter = iter(video_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(video_iter)\n",
    "j = json.load(open(osj(video_save_dir, x)))\n",
    "scores = np.asarray(list(j['scores'].values()))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores\n",
    "\n",
    "sparse sample is sampling 8 frames from 16 frames uniformly. Step is 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_save_dir = '../out/tsm_rep_scores_sparse_sample'\n",
    "video_json = os.listdir(video_save_dir)\n",
    "print(video_json[0])\n",
    "valtest = helper.get_rep_data(['val', 'test'], action=['all']).values()\n",
    "video_iter = iter(valtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(video_iter)\n",
    "json_path = x.video_name + '.score.json'\n",
    "j = json.load(open(osj(video_save_dir, json_path)))\n",
    "print(j['video_name'])\n",
    "gt_reps = np.array(j['ground_truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(gt_reps: np.ndarray, info: dict):\n",
    "    total_frames = j['total_frames']\n",
    "    ys = []\n",
    "    for item in list(j['scores'].values()):\n",
    "        ys.append([item[str(j)] if str(j) in item else 0 for j in range(12)])\n",
    "    ys = np.asarray(ys)\n",
    "    counts = len(gt_reps) // 2\n",
    "    GT_CLASS_INDEX = CLASSES.index(info['action'])\n",
    "    COLORS = list(plt.get_cmap('Set3').colors)\n",
    "    plt.plot(ys, marker='.', linestyle='None')\n",
    "    plt.xticks(range(0, total_frames//8, total_frames//80))\n",
    "    plt.xlabel('Frame index')\n",
    "    plt.ylabel('Softmax score')\n",
    "    plt.title(f\"{info['video_name']} {info['action']} count={counts}\")\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.vlines(x=gt_reps[0::2]//8, color=COLORS[GT_CLASS_INDEX*2], ymin=0.51, ymax=1.0)\n",
    "    plt.vlines(x=gt_reps[1::2]//8, color=COLORS[GT_CLASS_INDEX*2+1], ymin=0.0, ymax=0.49)\n",
    "    plt.legend(np.array(CLASSES).repeat(2))\n",
    "\n",
    "    # Indicator\n",
    "    segs = []\n",
    "    HEIGHT = 1.01\n",
    "    for i in range(len(gt_reps[::2])):\n",
    "        start = gt_reps[i*2]\n",
    "        end = gt_reps[i*2+1]\n",
    "        mid = (start + end) // 2\n",
    "        segs.append([(start//8, HEIGHT), (mid//8, HEIGHT)])\n",
    "        segs.append([(mid//8, HEIGHT), (end//8, HEIGHT)])\n",
    "    lc = LineCollection(segs, colors=[COLORS[GT_CLASS_INDEX*2], COLORS[GT_CLASS_INDEX*2+1]], linewidths=1)\n",
    "    plt.gca().add_collection(lc)\n",
    "    plt.show()\n",
    "\n",
    "def plot_per_action(CLASSES: list, info: dict):\n",
    "    total_frames = j['total_frames']\n",
    "    ys = []\n",
    "    for item in list(j['scores'].values()):\n",
    "        ys.append([item[str(j)] if str(j) in item else 0 for j in range(12)])\n",
    "    ys = np.asarray(ys)\n",
    "    fig, ax = plt.subplots(len(CLASSES), 1, figsize=(8, 8))\n",
    "    for idx in range(len(CLASSES)):\n",
    "        ax[idx].set_ylim(0, 1.1)\n",
    "        ax[idx].plot(ys[:, idx*2:idx*2+2])\n",
    "        ax[idx].set_title(f'{CLASSES[idx]}', y=0.95)\n",
    "        ax[idx].set_xticks(range(0, total_frames//8, total_frames//80))\n",
    "    plt.xlabel('Frame index')\n",
    "    plt.ylabel('Softmax score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workoutdetector.utils.inference_count import pred_to_count\n",
    "from workoutdetector.utils import plot_all, plot_per_action, plot_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_save_dir = '../out/tsm_lightning_sparse_sample'\n",
    "video_json = os.listdir(video_save_dir)\n",
    "print(video_json[0])\n",
    "valtest = helper.get_rep_data(['val', 'test'], action=['all']).values()\n",
    "video_iter = iter(valtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(video_iter)\n",
    "json_path = x.video_name + '.score.json'\n",
    "j = json.load(open(osj(video_save_dir, json_path)))\n",
    "print(j['video_name'])\n",
    "gt = np.array(j['ground_truth'])\n",
    "score = j['scores']\n",
    "threshold = 0.5\n",
    "# print(score.values())\n",
    "pred = []\n",
    "\n",
    "for v in score.values():\n",
    "    softmax_score = F.softmax(torch.Tensor(list(v.values())), dim=0)\n",
    "    max_idx = torch.argmax(softmax_score)\n",
    "    class_id, sc = max_idx.item(), softmax_score[max_idx].item()\n",
    "    if sc >= threshold:\n",
    "        pred.append(int(class_id))\n",
    "    else:\n",
    "        pred.append(-1)\n",
    "print(pred)\n",
    "result = pred_to_count(pred, step=8)\n",
    "print(result[1])\n",
    "print(f'gt={len(gt)//2}, pred={result[0]}')\n",
    "print('Absolute diff', abs(result[0] - len(gt)//2))\n",
    "\n",
    "plot_pred(result[1], gt, j['total_frames'], info=j, step=8)\n",
    "plot_all(gt, info=j, softmax=True)\n",
    "plot_per_action(info=j, softmax=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac44e3a5a0596b514731e2f84c219b304de7b3485523626a2f8b154e2423b93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
